\chapter{Contribuição: StarVZ sobre Spark} \label{ch:contribution}

A fase de pré-processamento do arcabouço StarVZ é similar a um fluxo de Ciência 
de dados. Nele, são carregadas e manipuladas várias tabelas, utilizando 
bibliotecas do pacote \texttt{tidyverse}. Este Capítulo fala sobre as diferenças 
propostas e realizadas no StarVZ, com o objetivo de otimizar o tempo de 
execução desta fase. Resumidamente, no lugar de tabelas R, utilizaremos tabelas
Spark (\emph{Spark Dataframes}) para o carregamento e manipulação de dados.
Na Seção \ref{sect:arch} são apresentadas as mudanças 
arquiteturais propostas e na Seção \ref{sect:implement}, detalha-se a 
implementação dessas mudanças.

\section{Arquitetura Proposta} \label{sect:arch}

A arquitetura da aplicação que este trabalho se propõe a modificar pode ser 
visualizada na Figura \ref{fig:starvz-app}.Os dados, já em formato CSV são lidos 
com a biblioteca \texttt{readr}. Com estes em memória, são realizadas filtragens 
e junções com o auxílio das bibliotecas \texttt{dplyr} e \texttt{tibble}. 
Finalmente, os dados são escritos em disco no formato \texttt{Feather}, usando a 
biblioteca de mesmo nome. Todo esse processo é conduzido através de um código R.

\begin{figure}[ht]
 \centerline{\includegraphics[width=1\textwidth]{./img/starvz-arch.pdf}}
 \caption{Arquitetura da aplicação StarVZ.}
 \label{fig:starvz-app}
\end{figure}

Durante o trabalho, identificou-se que não havia uma biblioteca que suportasse a 
escrita de tabelas Spark em arquivos \texttt{Feather}. Isso é essencial para 
compararmos a escrita do mesmo tipo de dados tanto na execução sequencial quanto 
na distribuída utilizando tabelas Spark. Devido ao ecossistema Hadoop utilizar 
o formato \texttt{Parquet} \cite{} como padrão para armazenamento de dados 
colunares, a aplicação foi adaptada para escrever suas saídas neste formato. 
Isso foi realizado utilizando a biblioteca Apache arrow \cite{}, a arquitetura 
final da aplicação sequencial pode ser visualizada na Figura 
\ref{fig:starvz-app-arrow}. 

\begin{figure}[ht]
 \centerline{\includegraphics[width=1\textwidth]{./img/starvz-arch-arrow.pdf}}
 \caption{Arquitetura da aplicação StarVZ adaptada para escrever Parquet.}
 \label{fig:starvz-app-arrow}
\end{figure}

A Figura \ref{fig:starvz-app-spark} ilustra a arquitetura da aplicação após as 
modificações propostas. Considerando o tamanho dos arquivos de entrada, 
utilizaremos o HDFS para armazená-lo. Todavia, alguns arquivos não crescem muito 
com o aumento do tamanho das entradas, ficando com o tamanho na ordem de KBytes. 
Para esses arquivos pequenos, o custo de armazená-los no sistema de arquivos e 
tratá-los no sistema de arquivos distribuído é maior do que armazená-los e 
trata-los sequencialmente e, por isso, seu armazenamento e tratamento continuou 
no formato sequencial. A escrita das saídas foi padronizada para escrever com o 
sparklyr no HDFS, dessa forma o usuário 
tem apenas uma fonte de saída.

\begin{figure}[ht]
 \centerline{\includegraphics[width=1\textwidth]{./img/starvz-arch-spark.pdf}}
 \caption{Arquitetura da aplicação StarVZ utilizando Spark.}
 \label{fig:starvz-app-spark}
\end{figure}

\section{Implementação} \label{sect:implement}

Para as alterações propostas, a biblioteca \texttt{sparklyr} foi escolhida 
para fazer a intermediação entre o código R e o Spark. De acordo com \citet{}, 
a abordagem dela prioriza a experiência com R, abstraindo alguns dos conceitos 
básicos como a seção Spark (\emph{Spark Session}), diferindo da abordagem padrão 
das APIs. Ela foi desenvolvida baseada no pacote \texttt{dplyr}, o que facilitou 
a adaptação da aplicação pois este era responsável pela maior parte das 
manipulações de tabelas.

Tratando-se dos detalhes de implementação, foi criado um novo arquivo com o 
fluxo de execução distribuída. Dessa forma, em um único pacote, o usuário pode 
optar por executar qualquer metodologia do arcabouço. Criou-se o parâmetro de 
tipo de execução, onde \texttt{-S} significa sequencial e \texttt{-D} significa 
distribuída, onde cada abordagem conta com parâmetros específicos.

\begin{figure}[ht]
 \centerline{\includegraphics[width=1\textwidth]{./img/applicationflow.pdf}}
 \caption{Fluxo de execução da aplicação.}
 \label{fig:spark-starvz-flow}
\end{figure}

As modificações realizadas tiveram o objetivo de otimizar o processamento das 
tabelas. A ordem como elas são processadas não foi alterada, como pode ser 
visualizado na Figura \ref{fig:spark-starvz-flow}.

Na parte sequencial, a única modificação foi a escrita de arquivos no formato 
\emph{Parquet}, com o pacote \texttt{arrow}. Em termos de código, essa 
modificação é bastante pontual, adicionando uma importação de biblioteca e 
modificando-se os métodos de escrita de arquivos (de \texttt{write\_feather} 
para \texttt{write\_parquet}). É importante salientar que este pacote também 
conta com uma implementação de \texttt{write\_feather}, que é mais eficiente 
que aquela do pacote \texttt{feather}.

A execução distribuída precisou uma expansão nos parâmetros para comportar o 
diretório no HDFS, o gerenciador de cluster e o local de instalação do Spark. 
Isso flexibiliza a aplicação, já que o usuário pode executar em diferentes 
gerenciadores de cluster (por exemplo, executar em um gerenciador local com 
cargas de trabalho pequenas e distríbuido com cargas de trabalho maiores, apenas 
mudando um parâmetro). A informação de diretório de entradas locais também é 
necessária, tendo em vista que o arquivo entities.csv é muito pequeno 
independente da execução e tratá-lo de forma distribuída não é vantajoso.

Primeiramente, é necessário estabelecer uma conexão com o \texttt{gerenciador 
de cluster}, utilizando o método \texttt{spark\_connect}. Com esta 
estabelecida, é possível ler arquivos em diversos formatos diretamente para 
tabelas no \texttt{sparklyr}. É importante ressaltar que com essa biblioteca, 
conseguimos ler arquivos armazenados no HDFS, o que permite que volumes de 
dados maiores que a quantidade de memória disponível na máquina sejam 
processados, o que não é possível na abordagem sequencial.

Com os arquivos carregados em tabelas \texttt{sparklyr} o restante do trabalho 
foi identificar equivalências entre manipulações realizadas com a 
\texttt{dplyr}. Ao encontrar uma manipulação, o seu resultado era observado na 
tabela original e reproduzido com funções suportadas pelo \texttt{sparklyr}. 
Isso é importante pois, caso fosse necessário um tratamento que não fosse 
suportado pela biblioteca, seria preciso implementá-lo. Isso seria realizado 
via funções definidas pelos usuários (\emph{User defined function ou UDFs}), 
todavia, essa funcionalidade sofre de problemas de desempenho nas linguagens R 
e Python pois há o custo adicional de criar um processo da linguagem e toda a 
comunicação de dados (serialização de entradas e saídas). Existe uma forma de 
otimização que seria implementar este comportamento em Scala ou Java, onde 
esses custos adicionais não existem.




O tratamento de entities foi realizado de forma sequencial, pois não 
observou-se alteração em seu tamanho nem mesmo em logs de onde o somatório dos 
demais arquivos eram de centenas de gigabytes. Todavia, para padronizarmos o 
local de saída, ele também foi escrito no mesmo diretório dos demais arquivos.





