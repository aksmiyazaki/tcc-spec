% resumo na língua do documento
\begin{abstract}
O StarVZ é um arcabouço para visualização de rastros de aplicações 
orientadas a tarefas no contexto de \textit{High-Performance Computing}. Ele é 
separado em duas fases, a primeira voltada para o pré-processamento dos dados e 
a segunda para a exibição. Essa primeira fase sofre de problemas de desempenho 
ao trabalhar com grandes volumes de dados. Este trabalho se propõe a utilizar o 
Hadoop e o Spark para otimizar o processamento mais custoso desta fase. Este 
consiste em um fluxo de Ciência de Dados utilizando a linguagem R, o que 
facilitou bastante sua portagem para manipulação de dados via Spark. Nos 
resultados observados utilizando uma carga de trabalho de 12 gigabytes e 3 nós 
computacionais, cada um com 15 executores, chegamos a reduzir o tempo de 
execução em 74,11\% comparado com a execução sequencial.
\end{abstract}

% resumo na outra língua
% como parametros devem ser passados o titulo e as palavras-chave
% na outra língua, separadas por vírgulas
\begin{englishabstract}{Improving StarVZ to handle Big Data}{Spark, 
Hadoop, StarVZ}
StarVZ is a framework for trace visualization of High-Performance Computing 
task-based applications. It is divided in two phases. The first one aims the 
data pre-processing whereas the second one aims the visualization. The 
first phase suffers from performance issues when handling large application 
traces and many gigabytes. This work proposes the utilization of Hadoop and 
Spark to optimize the most expensive step of this phase. It consists of a Data 
Science workflow using the R language, which eases its adaptation to Spark. In 
the observed results, with a 12 gigabytes workload and 3 nodes, each one with 
15 executors, we managed to reduce the execution time in 74,11\% comparing with 
the sequential execution.
\end{englishabstract}

