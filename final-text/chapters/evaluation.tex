\chapter{Resultados e Avaliação} \label{ch:evaluation}

A avaliação dos resultados foi realizada no Parque Computacional de Alto 
Desempenho (PCAD) da UFRGS. Os experimentos ocorreram unicamente nos nós de 
computação draco, onde cada nó possui a configuração mostrada na Tabela 
\ref{tab:draco_config}.

\begin{table}[H]
\centering
\begin{tabular}{l l} \toprule
\textbf{Parâmetro}  &  \textbf{Configuração} \\ 
\midrule
Processador     & 2 x Intel Xeon E5-2630 (Q1'12) Sandy Bridge, 2,5 GHz  
\\
Número de Núcleos    & 16 núcleos (8 por CPU)  \\
Memória       & 64 GB DDR3 RAM   \\
\end{tabular}
\caption{Configurações dos nós draco.}
\label{tab:draco_config}
\end{table}

A carga de trabalho dos experimentos já no formato CSV (entrada para a fase de 
pré-processamento no StarVZ), tinha um somatório de 12 GB. Ela consiste em 
rastros de execução de uma aplicação Cholesky, e foi escolhida pois era a maior
entrada que tínhamos no momento. O tamanho de cada um dos arquivos pode ser 
visualizado na Tabela \ref{tab:input_sz}.

\begin{table}[H]
\centering
\begin{tabular}{l c} \toprule
\textbf{Arquivo}  &  \textbf{Tamanho} \\ 
\midrule
state.csv	& 6.8 GB \\
variables.csv  	& 2.5 GB \\
link.csv       	& 304 MB \\
dag.csv        	& 270 MB \\
entities.csv	& 73 KB \\
events.csv	& 1.8 GB \\
\textbf{Total}  & 12 GB  \\
\end{tabular}
\caption{Detalhamento da carga de trabalho.}
\label{tab:input_sz}
\end{table}

Foram executados testes com um, dois e três nós com essa mesma carga de 
trabalho. Para os distribuídos, armazenou-se os dados no HDFS, mas por 
facilidade de análise ao invés de utilizar o YARN como gerenciador de cluster 
utilizou-se o próprio Spark pois seus logs eram mais claros. Isso evidencia a 
flexibilidade que a engine Spark fornece pois, com um simples parâmetro, 
muda-se quem faz a gerência dos recursos ao executar a aplicação.



