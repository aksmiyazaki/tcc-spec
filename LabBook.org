#+STARTUP: overview indent

* Estrutura do texto final
** Recomendação #1
Sobre a estrutura, entendo o enfoques que queres dar com a parte de
visualização (clássica ou task-based) mas acredito que esse enfoque é
secundário no teu trabalho. A fundamentação teórica, que eu preferiria
chamar de "conceitos básicos" e "trabalhos relacionados",
potencialmente em capítulos diferentes, consistiria em detalhar (nos
conceitos básicos) a forma com o workflow do starvz funciona de
maneira sequencial e em formas de paralelização/distribuição de
workflows (de maneira abstrata, mas eventualmente citando algumas
ferramentas). Em trabalhos relacionados, apresentar tentativas
anteriores de paralelização para o StarVZ tais como o trabalho do
Guilherme Alles [1], que usou Drake, explicando por que não funcionou,
e depois outras alternativas de paralelização (sem o uso de
Hadoop/MapReduce). Essas outras alternativas de
paralelização/distribuição podem ser consultadas no [2], detalhando
pelo menos umas três alternativas de "Explicit parallelism " e
"Implicit parallelism ". No final desta parte "conceitos básicos" e
"trabalhos relacionados", tu apresentas então uma "Discussão e
Motivação", na forma da última subseção antes da tua contribuição onde
tu detalhas os porquês das tuas escolhas com Hadoop/MapReduce,
trazendo eventualmente para a discussão o fato que starvz está
implementado em dplyr+tidyverse e que o sparklyr que encapsula boa
parte das ações já funciona como uma interface para o
Hadoop/MapReduce. Em seguida, então, vem o capítulo da "Contribuição:
Implementando StarVZ sobre Hadoop/MapReduce". Ali tu vais detalhar o
funcionamento geral (arquitetura) da tua contribuição e quais foram as
mudanças feitas no StarVZ (as menores possíveis). Tu notas que o que
tu chamas de "metodologia" entra, de uma forma ou de outra, neste
capítulo descrevendo a forma como o objetivo (lá da intro) foi
atingido. Enfim, os experimentos e conclusão são detalhados embora o
conteúdo dependa ainda do que será alcançado. Penso que a parte da
configuração experimental já possa ser estrutura com os estudos de
caso, etc.
** 2019-06-08 Versão
    SUMÁRIO
    1 INTRODUÇÃO...........................................................................................................11
    2 FUNDAMENTAÇÃO..................................................................................................13
    2.1 Conceitos Básicos ....................................................................................................13
    2.2 Trabalhos Relacionados..........................................................................................13
    3 CONTRIBUIÇÃO.......................................................................................................14
    3.1 Discussão e Motivação ............................................................................................14
    3.2 Implementação e Avaliação....................................................................................14
    4 CONCLUSÃO E TRABALHOS FUTUROS ...........................................................15
    REFERÊNCIAS.............................................................................................................16
** Recomendação #2

Conteúdo de 2.1 portanto:
- a forma com o workflow do starvz funciona de maneira sequencial e em
  formas de paralelização/distribuição de workflows (de maneira
  abstrata, mas eventualmente citando algumas ferramentas).
Conteúdo de 2.2 portanto:
- apresentar tentativas anteriores de paralelização para o StarVZ tais
  como o trabalho do Guilherme Alles [1], que usou Drake, explicando
  por que não funcionou, e depois outras alternativas de paralelização
  (sem o uso de Hadoop/MapReduce). Essas outras alternativas de
  paralelização/distribuição podem ser consultadas no [2], detalhando
  pelo menos umas três alternativas de "Explicit parallelism " e
  "Implicit parallelism "
Conteúdo de 3.1 portanto:
- tu detalhas os porquês das tuas escolhas com Hadoop/MapReduce,
  trazendo eventualmente para a discussão o fato que starvz está
  implementado em dplyr+tidyverse e que o sparklyr que encapsula boa
  parte das ações já funciona como uma interface para o
  Hadoop/MapReduce

Sugestões:
- [X] Mudar o título de 3 para algo como "Contribuição: Implementando StarVZ sobre Hadoop/MapReduce"
- R - Não adotei o nome inteiro pois ficaria muito extenso (mais de 1 linha no sumário).
- [X] Adicionar uma seção 3.2 com a visão geral da arquitetura:
  - tu vais detalhar o funcionamento geral (arquitetura) da tua
    contribuição e quais foram as mudanças feitas no StarVZ (as
    menores possíveis).
- [X] Adicionar uma seção 3.3 com o detalhamento da implementação
  - Detalhes técnicos
- [X] O que tu imaginas como "Avaliação" tu colocas em um capítulo próprio, "4 RESULTADOS E AVALIAÇÃO"
  - Neste capítulo, os experimentos são detalhados embora o conteúdo
    dependa ainda do que será alcançado. Penso que a parte da
    configuração experimental já possa ser estruturada com os estudos
    de caso, etc.
- [X] O atual Cap. 4 se torna Cap. 5 (Conclusão e Trabs. Fut.)

** 2019-07-08 Revisão do TCC
*** Traduções
Os termos em inglês devem ser traduzidos.
Exemplos:
- "task-based" para baseado em tarefas
- "traces" para *rastros*
- "framework" para arcabouço
- "runtime" para ambiente de execução, mas manter a palavra /runtime/
  em itálico depois do termo em português.
- "performance" para desempenho (todos os lugares)
- "workflow" -> para fluxo de processamento
- "Execution Traces" -> rastros de execução
- "Trace" -> rastro
- "states" -> estados, eventos -> eventos, ... (cap.2)
- Traduzir Comma-Separated Value (CSV)
- "data frame" -> tabela
- "usability wrapper"
- Evitar palavras em inglês em geral, procurando uma boa tradução e
  colocando a palavra em inglês em itálico dentro de parenteses na
  primeira ocorrência.
*** Capítulo 1 (Introdução)
- Parágrafo #2: além da heterogeneidade _interna_ dos nós computacionais
  que motiva o uso de DAG como aplicações, temos também a natural
  "variabilidade" do desempenho de sistemas computacionais que em
  escala podem prejudicar ambientes de execução que precisam que as
  aplicações tenho um particionamento estático e regular.
- "não são eficazes ao analisar aplicações baseadas em tarefas." por
  não ter elementos visuais e métricas que consideram o grafo de
  tarefas da aplicação.
- "foi desenvolvido combinando ~pj_dump~" \to talvez valha a pena dizer
  que faz parte do PajeNG e citar o trabalho
- "em alguns estudos de caso onde o StarVZ foi utilizado, contribuíram"
  refrasear para evitar separação de sujeito e verbo
- "Serão utilizadas ferramentas de Big Data para essa otimização."
  - Quais ferramentas? Qual a abordagem?
- Reservar um parágrafo antes da estrutura para listar um sumário dos
  resultados obtidos quando estes estiverem atingidos.
- Quebrar o parágrafo da estrutura do texto em múltiplas frases.
*** Capítulo 2 (Fundamentação)
- "discute-se sobre os trabalhos relacionados." -> são apresentados
  - Quebrar em duas frases
- Fig 2.1: aumentar as letras pois parecem pequenas demais quando
  comparadas ao texto normal do documento
- "com informação de data e hora" -> eventos datados
- Colocar na lista de abreviaturas
  - Comma-Separated Value (CSV)
- "dados da execução inteira são unificados em uma estrutura" -> os
  dados são unificados em uma lista
- "customizada." -> configurável
- "Nele utilizou-se" (juntar com o parágrafo anterior)
- Os desenvolvedores do drake evoluiram o software para evitar
  checkpoint em disco (conforme [1]) em algo chamado como "hasty
  mode", mas isso ainda não foi avaliado no âmbito do StarVZ (com
  suporte à drake).
  [1]: https://github.com/schnorr/starvz/issues/6
- "básicamente"

Visão geral Cap 2: Tenho a percepção que a "fundamentação teórica"
está demasiada curta. Poderias incorporar uma parte do texto que havia
sido preparado na proposta. Poderias falar rapidamente sobre o
ferramental BigData (Hadoop & friends). Sugestão de mudança interna.

2. Fundamentação
- Pequena introdução
2.1 Análise de Desempenho de Aplicações Paralelas
- Tudo o que constava na fundamentação da proposta
2.1.1 Ferramentas de Viz. Clássica
2.1.2 Ferramentas de Viz para aplic orientadas a tarefas
- Com exceção de StarVZ (ver abaixo capítulo exclusivo), deixar
  portanto apenas uma menção que maiores detalhamentos serão lá
  colocados
2.2 Universo de ferramentas MapReduce
- Incluindo a filosofia de paralelização de IO
  - Múltiplos discos, etc
  - Explicar MR, e Spark (com o DAG)

(NOVO Capítulo) A Ferramenta StarVZ
X.1 Visão Geral
- Tudo o que já tem na atual 2.1 Conceitos Básicos, mais:
  - Texto sobre StarVZ na última seção não numerada da Seção
    Fundamentação da proposta incluindo a Figura 2.1 da proposta e
    texto adjacente
X.2 Fases
- A Figura 3.1 da proposta e texto adjacente
  - Explicar mais detalhadamente a figura
X.3 Trabalhos Relacionados
- Tudo o que esta hoje na Seção 2.2 Trabs. Relacionados
X.4 Motivação/Abordagem
- Motivar o trabalho argumento que as soluções atuais não são
  escaláveis e que há uma necessidade de se avaliar se ferramentas de
  big data podem resolver o problema
- Explicitar bem rapidamente a abordagem
- Gancho para o próximo capítulo
* Instalação do StarPU

** Manualmente

Veja este site:
https://github.com/schnorr/starvz/blob/master/INSTALL.org

Procure diretamente a seção com o título "StarPU, fxt, and poti" e
siga os três passos lá descritos:

1. Install the latest version of FXT
2. Install poti
3. Install StarPU from the SVN

** "Automaticamente" (preferível)
*** Instalar Spack em $HOME

#+begin_src shell :results output
cd $HOME
git clone https://github.com/spack/spack.git
source ./spack/share/spack/setup-env.sh 
spack --help
#+end_src

Para registrar o comando ~spack~ no ~PATH~, basta:

#+begin_src shell :results output
export PATH=$PATH:$HOME/spack/bin/
spack --help
#+end_src

*** Instalar um repositório "extra" com suplementos (starpu & friends)

Mais informações:
https://gitlab.inria.fr/solverstack/spack-repo

Receita:

#+begin_src shell :results output
INSTALL_DIR=$HOME/solverstack-spack/
git clone https://gitlab.inria.fr/solverstack/spack-repo.git $INSTALL_DIR
spack repo add $INSTALL_DIR
#+end_src

Seguir os demais comandos normalmente.

*** Instalar starpu 1.3.1 com fxt e poti, sem mpi

O símbolo `+` indica que a opção é selecionada.

O símbolo `~` indica que a opção _não_ é selecionada.

#+begin_src shell :results output
spack install starpu@1.3.1+fxt+poti~cuda~simgrid~mpi
#+end_src

*** Como usar ~starpu_fxt_tool~

Assumindo que o comando ~spack~ já está no teu ~PATH~.

Basta fixar no teu ~PATH~ o resultado do seguinte comando:

#+begin_src shell :results output
echo $(spack location -i starpu@1.3.1)/bin
#+end_src

Com algo como:

#+begin_src shell :results output
export PATH=$PATH:$(spack location -i starpu@1.3.1)/bin
#+end_src

Teste:

#+begin_src shell :results output
starpu_fxt_tool --help
#+end_src
* FXT \to CSV
Obter apenas arquivos CSV (sem executar a parte em R da primeira fase).

Exemplo com ~qrmumps~.

#+begin_src shell :results output
source ~/spack/share/spack/setup-env.sh 
export PATH=$(spack location -i starpu@develop~cuda~examples+fast~fortran+fxt+mlr~mpi~nmad~opencl+openmp+poti+shared~simgrid~simgridmc~verbose)/bin/:$PATH
export PATH=$PATH:~/dev/starvz/src/
export PATH=$PATH:~/dev/pajeng/b/

# Ir para o diretório que contém o arquivo prof_file e atree.dot
cd /tmp/qrmumps 
# O script foi editado manualmente para não chamar o programa em R da fase 1
phase1-workflow.sh . qrmumps
#+end_src


