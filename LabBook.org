#+STARTUP: overview indent

* Estrutura do texto final
** Recomendação #1
Sobre a estrutura, entendo o enfoques que queres dar com a parte de
visualização (clássica ou task-based) mas acredito que esse enfoque é
secundário no teu trabalho. A fundamentação teórica, que eu preferiria
chamar de "conceitos básicos" e "trabalhos relacionados",
potencialmente em capítulos diferentes, consistiria em detalhar (nos
conceitos básicos) a forma com o workflow do starvz funciona de
maneira sequencial e em formas de paralelização/distribuição de
workflows (de maneira abstrata, mas eventualmente citando algumas
ferramentas). Em trabalhos relacionados, apresentar tentativas
anteriores de paralelização para o StarVZ tais como o trabalho do
Guilherme Alles [1], que usou Drake, explicando por que não funcionou,
e depois outras alternativas de paralelização (sem o uso de
Hadoop/MapReduce). Essas outras alternativas de
paralelização/distribuição podem ser consultadas no [2], detalhando
pelo menos umas três alternativas de "Explicit parallelism " e
"Implicit parallelism ". No final desta parte "conceitos básicos" e
"trabalhos relacionados", tu apresentas então uma "Discussão e
Motivação", na forma da última subseção antes da tua contribuição onde
tu detalhas os porquês das tuas escolhas com Hadoop/MapReduce,
trazendo eventualmente para a discussão o fato que starvz está
implementado em dplyr+tidyverse e que o sparklyr que encapsula boa
parte das ações já funciona como uma interface para o
Hadoop/MapReduce. Em seguida, então, vem o capítulo da "Contribuição:
Implementando StarVZ sobre Hadoop/MapReduce". Ali tu vais detalhar o
funcionamento geral (arquitetura) da tua contribuição e quais foram as
mudanças feitas no StarVZ (as menores possíveis). Tu notas que o que
tu chamas de "metodologia" entra, de uma forma ou de outra, neste
capítulo descrevendo a forma como o objetivo (lá da intro) foi
atingido. Enfim, os experimentos e conclusão são detalhados embora o
conteúdo dependa ainda do que será alcançado. Penso que a parte da
configuração experimental já possa ser estrutura com os estudos de
caso, etc.
** 2019-06-08 Versão
    SUMÁRIO
    1 INTRODUÇÃO...........................................................................................................11
    2 FUNDAMENTAÇÃO..................................................................................................13
    2.1 Conceitos Básicos ....................................................................................................13
    2.2 Trabalhos Relacionados..........................................................................................13
    3 CONTRIBUIÇÃO.......................................................................................................14
    3.1 Discussão e Motivação ............................................................................................14
    3.2 Implementação e Avaliação....................................................................................14
    4 CONCLUSÃO E TRABALHOS FUTUROS ...........................................................15
    REFERÊNCIAS.............................................................................................................16
** Recomendação #2

Conteúdo de 2.1 portanto:
- a forma com o workflow do starvz funciona de maneira sequencial e em
  formas de paralelização/distribuição de workflows (de maneira
  abstrata, mas eventualmente citando algumas ferramentas).
Conteúdo de 2.2 portanto:
- apresentar tentativas anteriores de paralelização para o StarVZ tais
  como o trabalho do Guilherme Alles [1], que usou Drake, explicando
  por que não funcionou, e depois outras alternativas de paralelização
  (sem o uso de Hadoop/MapReduce). Essas outras alternativas de
  paralelização/distribuição podem ser consultadas no [2], detalhando
  pelo menos umas três alternativas de "Explicit parallelism " e
  "Implicit parallelism "
Conteúdo de 3.1 portanto:
- tu detalhas os porquês das tuas escolhas com Hadoop/MapReduce,
  trazendo eventualmente para a discussão o fato que starvz está
  implementado em dplyr+tidyverse e que o sparklyr que encapsula boa
  parte das ações já funciona como uma interface para o
  Hadoop/MapReduce

Sugestões:
- [X] Mudar o título de 3 para algo como "Contribuição: Implementando StarVZ sobre Hadoop/MapReduce"
- R - Não adotei o nome inteiro pois ficaria muito extenso (mais de 1 linha no sumário).
- [X] Adicionar uma seção 3.2 com a visão geral da arquitetura:
  - tu vais detalhar o funcionamento geral (arquitetura) da tua
    contribuição e quais foram as mudanças feitas no StarVZ (as
    menores possíveis).
- [X] Adicionar uma seção 3.3 com o detalhamento da implementação
  - Detalhes técnicos
- [X] O que tu imaginas como "Avaliação" tu colocas em um capítulo próprio, "4 RESULTADOS E AVALIAÇÃO"
  - Neste capítulo, os experimentos são detalhados embora o conteúdo
    dependa ainda do que será alcançado. Penso que a parte da
    configuração experimental já possa ser estruturada com os estudos
    de caso, etc.
- [X] O atual Cap. 4 se torna Cap. 5 (Conclusão e Trabs. Fut.)

** 2019-07-08 Revisão do TCC
*** Traduções
Os termos em inglês devem ser traduzidos.
Exemplos:
- "task-based" para baseado em tarefas
- "traces" para *rastros*
- "framework" para arcabouço
- "runtime" para ambiente de execução, mas manter a palavra /runtime/
  em itálico depois do termo em português.
- "performance" para desempenho (todos os lugares)
- "workflow" -> para fluxo de processamento
- "Execution Traces" -> rastros de execução
- "Trace" -> rastro
- "states" -> estados, eventos -> eventos, ... (cap.2)
- Traduzir Comma-Separated Value (CSV)
- "data frame" -> tabela
- "usability wrapper"
- Evitar palavras em inglês em geral, procurando uma boa tradução e
  colocando a palavra em inglês em itálico dentro de parenteses na
  primeira ocorrência.
*** Capítulo 1 (Introdução)
- Parágrafo #2: além da heterogeneidade _interna_ dos nós computacionais
  que motiva o uso de DAG como aplicações, temos também a natural
  "variabilidade" do desempenho de sistemas computacionais que em
  escala podem prejudicar ambientes de execução que precisam que as
  aplicações tenho um particionamento estático e regular.
- "não são eficazes ao analisar aplicações baseadas em tarefas." por
  não ter elementos visuais e métricas que consideram o grafo de
  tarefas da aplicação.
- "foi desenvolvido combinando ~pj_dump~" \to talvez valha a pena dizer
  que faz parte do PajeNG e citar o trabalho
- "em alguns estudos de caso onde o StarVZ foi utilizado, contribuíram"
  refrasear para evitar separação de sujeito e verbo
- "Serão utilizadas ferramentas de Big Data para essa otimização."
  - Quais ferramentas? Qual a abordagem?
- Reservar um parágrafo antes da estrutura para listar um sumário dos
  resultados obtidos quando estes estiverem atingidos.
- Quebrar o parágrafo da estrutura do texto em múltiplas frases.
*** Capítulo 2 (Fundamentação)
- "discute-se sobre os trabalhos relacionados." -> são apresentados
  - Quebrar em duas frases
- Fig 2.1: aumentar as letras pois parecem pequenas demais quando
  comparadas ao texto normal do documento
- "com informação de data e hora" -> eventos datados
- Colocar na lista de abreviaturas
  - Comma-Separated Value (CSV)
- "dados da execução inteira são unificados em uma estrutura" -> os
  dados são unificados em uma lista
- "customizada." -> configurável
- "Nele utilizou-se" (juntar com o parágrafo anterior)
- Os desenvolvedores do drake evoluiram o software para evitar
  checkpoint em disco (conforme [1]) em algo chamado como "hasty
  mode", mas isso ainda não foi avaliado no âmbito do StarVZ (com
  suporte à drake).
  [1]: https://github.com/schnorr/starvz/issues/6
- "básicamente"

Visão geral Cap 2: Tenho a percepção que a "fundamentação teórica"
está demasiada curta. Poderias incorporar uma parte do texto que havia
sido preparado na proposta. Poderias falar rapidamente sobre o
ferramental BigData (Hadoop & friends). Sugestão de mudança interna.

2. Fundamentação
- Pequena introdução
2.1 Análise de Desempenho de Aplicações Paralelas
- Tudo o que constava na fundamentação da proposta
2.1.1 Ferramentas de Viz. Clássica
2.1.2 Ferramentas de Viz para aplic orientadas a tarefas
- Com exceção de StarVZ (ver abaixo capítulo exclusivo), deixar
  portanto apenas uma menção que maiores detalhamentos serão lá
  colocados
2.2 Universo de ferramentas MapReduce
- Incluindo a filosofia de paralelização de IO
  - Múltiplos discos, etc
  - Explicar MR, e Spark (com o DAG)

(NOVO Capítulo) A Ferramenta StarVZ
X.1 Visão Geral
- Tudo o que já tem na atual 2.1 Conceitos Básicos, mais:
  - Texto sobre StarVZ na última seção não numerada da Seção
    Fundamentação da proposta incluindo a Figura 2.1 da proposta e
    texto adjacente
X.2 Fases
- A Figura 3.1 da proposta e texto adjacente
  - Explicar mais detalhadamente a figura
X.3 Trabalhos Relacionados
- Tudo o que esta hoje na Seção 2.2 Trabs. Relacionados
X.4 Motivação/Abordagem
- Motivar o trabalho argumento que as soluções atuais não são
  escaláveis e que há uma necessidade de se avaliar se ferramentas de
  big data podem resolver o problema
- Explicitar bem rapidamente a abordagem
- Gancho para o próximo capítulo
** 2019-07-19 Revisão do TCC
*** Capítulo 2 (Fundamentação)
- O índice ficou poluído com a lista de ferramentas de 2.1.1 e 2.1.2
  - Para resolver, remover a presença na TOC através de um comando do tipo
    #+BEGIN_EXPORT latex
    \subsubsection*{DAGViz}
    #+END_EXPORT
    ao invés de
    #+BEGIN_EXPORT latex
    \subsubsection{DAGViz}
    #+END_EXPORT
    Perceba o ~*~.
*** Capítulo 3 (StarVZ)
- Podes dizer que StarVZ é a única ferramenta que emprega ferramentas
  desenvolvidas para Data Science para se realizar análise de
  desempenho.
- genéricamente não tem acento
- "de forma detalhadas" cuidar concordância
- Em PT-BR, usar "rastros" ao invés de "traços" (do inglês trace)
3.1
- Suavizar a afirmação que starvz é a mais avançada
- remover itemize no segundo parágrafo, integrar em um único parágrafo
  separado por ponto-e-vírgulas.
- Fig 3.1: usar linhas pretas entre os blocos para diferenciar dos  blocos
3.3
- "que os mesmo problemas"
- Remover o "; e etc." no final de 3.3
3.4
- "esta Fase do fluxo"
* Instalação do StarPU

** Manualmente

Veja este site:
https://github.com/schnorr/starvz/blob/master/INSTALL.org

Procure diretamente a seção com o título "StarPU, fxt, and poti" e
siga os três passos lá descritos:

1. Install the latest version of FXT
2. Install poti
3. Install StarPU from the SVN

** "Automaticamente" (preferível)
*** Instalar Spack em $HOME

#+begin_src shell :results output
cd $HOME
git clone https://github.com/spack/spack.git
source ./spack/share/spack/setup-env.sh 
spack --help
#+end_src

Para registrar o comando ~spack~ no ~PATH~, basta:

#+begin_src shell :results output
export PATH=$PATH:$HOME/spack/bin/
spack --help
#+end_src

*** Instalar um repositório "extra" com suplementos (starpu & friends)

Mais informações:
https://gitlab.inria.fr/solverstack/spack-repo

Receita:

#+begin_src shell :results output
INSTALL_DIR=$HOME/solverstack-spack/
git clone https://gitlab.inria.fr/solverstack/spack-repo.git $INSTALL_DIR
spack repo add $INSTALL_DIR
#+end_src

Seguir os demais comandos normalmente.

*** Instalar starpu 1.3.1 com fxt e poti, sem mpi

O símbolo `+` indica que a opção é selecionada.

O símbolo `~` indica que a opção _não_ é selecionada.

#+begin_src shell :results output
spack install starpu@1.3.1+fxt+poti~cuda~simgrid~mpi
#+end_src

*** Como usar ~starpu_fxt_tool~

Assumindo que o comando ~spack~ já está no teu ~PATH~.

Basta fixar no teu ~PATH~ o resultado do seguinte comando:

#+begin_src shell :results output
echo $(spack location -i starpu@1.3.1)/bin
#+end_src

Com algo como:

#+begin_src shell :results output
export PATH=$PATH:$(spack location -i starpu@1.3.1)/bin
#+end_src

Teste:

#+begin_src shell :results output
starpu_fxt_tool --help
#+end_src
* FXT \to CSV
Obter apenas arquivos CSV (sem executar a parte em R da primeira fase).

Exemplo com ~qrmumps~.

#+begin_src shell :results output
source ~/spack/share/spack/setup-env.sh 
export PATH=$(spack location -i starpu@develop~cuda~examples+fast~fortran+fxt+mlr~mpi~nmad~opencl+openmp+poti+shared~simgrid~simgridmc~verbose)/bin/:$PATH
export PATH=$PATH:~/dev/starvz/src/
export PATH=$PATH:~/dev/pajeng/b/

# Ir para o diretório que contém o arquivo prof_file e atree.dot
cd /tmp/qrmumps 
# O script foi editado manualmente para não chamar o programa em R da fase 1
phase1-workflow.sh . qrmumps
#+end_src


* 2019-08-07 Resultados 1, 2 e 3 nós                                 :ATTACH:
:PROPERTIES:
:Attachments: extracted_results.csv
:ID:       4805b96f-99c4-4729-a5bd-ef5aad730e13
:END:


** Leitura

#+name: map
| Exec   | P |
|--------+---|
| seq    | 1 |
| d2node | 2 |
| d3node | 3 |

#+header: :var map=map
#+begin_src R :results output :session :exports both
library(tidyverse)
FILE <- "data/48/05b96f-99c4-4729-a5bd-ef5aad730e13/extracted_results.csv"
read_csv(FILE, col_types=cols()) %>% select(-X1, -Write) %>%
    # Create new column P with number of nodes
    left_join(map, by="Exec") %>% select(P, everything(), -Exec) %>%
    # Remove total values
    select(-Total) %>%
    # Tidy data
    gather(Variable, Value, -P) %>%
    # Group and Summarize (mean, error, etc)
    group_by(P, Variable) %>%
    summarize(N=n(),
              Mean = mean(Value),
              Error = 3*sd(Value)/sqrt(N)) %>%
    print -> df
#+end_src

#+RESULTS:
#+begin_example

# A tibble: 24 x 5
# Groups:   P [3]
       P Variable     N    Mean  Error
   <int> <chr>    <int>   <dbl>  <dbl>
 1     1 DAG         30   69.1  0.850 
 2     1 Entities    30    3.08 0.163 
 3     1 Events      30   89.9  0.912 
 4     1 GAPS        30   71.5  1.84  
 5     1 Link        30    8.93 0.170 
 6     1 Parsing     30 1327.   5.65  
 7     1 State       30  873.   4.90  
 8     1 Variable    30  211.   1.40  
 9     2 DAG         29    7.33 0.118 
10     2 Entities    29    2.29 0.0581
# … with 14 more rows
Warning message:
Missing column names filled in: 'X1' [1]
#+end_example

#+begin_src R :results output graphics :file img/preliminary-results.png :exports both :width 280 :height 400 :session
df %>%
    ggplot(aes(x=P, y=Mean, fill=Variable)) +
    geom_bar(stat="identity") +
    scale_fill_brewer(palette = "Set1", guide = guide_legend(nrow=4)) +
    theme_bw(base_size=22) +
    theme(plot.margin = unit(c(0,0,0,0), "mm"),
          legend.position="top",
          legend.justification = "left",
          legend.spacing = unit(0, "mm"),
          legend.box.spacing = unit(0, "pt"),
          legend.box.margin = margin(0,0,0,0),
          legend.margin = unit(c(0,0,0,0), "cm"),
          legend.title = element_blank()) +
    ylab("Time (s)") +
    xlab("Processing Units")
#+end_src

#+RESULTS:
[[file:img/preliminary-results.png]]


** Feedback dos gráficos enviados por e-mail


Sobre os gráficos, tem três:
- total_relative
- total_step
- total

Dicas gerais, (1) a fonte dos textos nos gráficos deve ser
maior. Podes fazer com theme_bw(base_size=22) por exemplo. Ajustar o
valor 22. Para saber o tamanho "ideal", basta comparar com o texto
normal uma vez a figura for colocada no manuscrito. O tamanho da fonte
do gráfico deve ser ligeiramente menor que aquela do texto normal. (2)
No eixo X, colocar 1, 2 e 3. Ajustar o label do eixo para dizer
"Quantidade de nós". A dúvida que fiquei agora diz respeito ao uso de
workers. No caso do spark (2 e 3 nós), tu usas vários workers por nó
ou apenas um? Acho que se a resposta for vários, valeria talvez a pena
usar a quantidade de workers, para ter uma ideia do potencial de
aceleração. (3) Melhorar as cores, utilizando o Set1 do color_brewer
para o fill.

Sobre os gráficos em si, as informações são as mesmas, eu ficaria
apenas com o gráfico total_step, com a discretização interna das
etapas. O problema do emprego de tempos relativos (total_relative) é
que eles funcionam bem somente para caso a caso (1, 2 ou 3), mas a
figura leva a uma comparação entre 1 e 2 por exemplo, algo que não faz
nenhum sentido pois as dimensões entre casos (1 e 2) não são
comparáveis. Por exemplo, a área rosa dá uma ideia de aumento (de 1
para 2 e 3), quando na realidade ela ficou menor. Outro exemplo, a
área rosa dá uma ideia de estabilidade (de 2 para 3) quando novamente
ela ficou menor em 3.

Se tu tens um controle mais fino da quantidade de workers por nós, o
que tu poderias fazer para ter mais informação a respeito da
escalabilidade é averiguar (mais testes!) com 2, 3, 4, 5, 6, 7, 8,
... até 40 workers (um por core em duas dracos por exemplo) ou
até 60. Claro que isso se o item (2) da dicas gerais se averiguar.

Ainda não tive tempo de me debruçar sobre o capítulo de
contribuições. Mas estou quase lá. Vai me atualizando.
